import hashlib
import os
__version__ = "2.0.0"
import sys
import json
import time
import argparse
import logging
import psutil
import cv2
import re
import textwrap
import base64
import numpy as np
import yake
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from huggingface_hub import hf_hub_download
from llama_cpp import Llama
from llama_cpp.llama_chat_format import Llava15ChatHandler
from tqdm import tqdm

# --- Configuration Constants ---
REPO_ID = "ggml-org/SmolVLM2-500M-Video-Instruct-GGUF"
CONTEXT_SIZE = 8192
DEFAULT_DEBUG_DIR = "debug_frames"
CACHE_DIR = os.path.expanduser("~/.cache/bo_video_tagger/models")

# Setup Logger (Configured in main)
logger = logging.getLogger("VideoTagger")

@dataclass
class ModelConfig:
    filename: str
    mmproj: str
    desc: str
    min_ram_gb: float
    sha256: str
    mmproj_sha256: str

MODEL_TIERS = {
    "smart": ModelConfig(
        filename="SmolVLM2-500M-Video-Instruct-Q8_0.gguf",
        mmproj="mmproj-SmolVLM2-500M-Video-Instruct-Q8_0.gguf",
        desc="Balanced (Q8 Quantization)",
        min_ram_gb=2.5,
        sha256="6f67b8036b2469fcd71728702720c6b51aebd759b78137a8120733b4d66438bc",
        mmproj_sha256="921dc7e259f308e5b027111fa185efcbf33db13f6e35749ddf7f5cdb60ef520b"
    ),
    "super": ModelConfig(
        filename="SmolVLM2-500M-Video-Instruct-f16.gguf",
        mmproj="mmproj-SmolVLM2-500M-Video-Instruct-f16.gguf",
        desc="Max Precision (F16 - Lossless)",
        min_ram_gb=4.0,
        sha256="80f7e3f04bc2d3324ac1a9f52f5776fe13a69912adf74f8e7edacf773d140d77",
        mmproj_sha256="b5dc8ebe7cbeab66a5369693960a52515d7824f13d4063ceca78431f2a6b59b0"
    )
}

class VideoTagger:
    def __init__(self, tier: str = "smart", debug: bool = False, interval: int = 10, unsafe: bool = False):
        self.interval = interval
        self.debug = debug
        self.unsafe = unsafe
        self.tier_name = tier
        
        if tier not in MODEL_TIERS:
            raise ValueError(f"Invalid tier: {tier}. Choices: {list(MODEL_TIERS.keys())}")
            
        self.config = MODEL_TIERS[tier]
        self.model_dir = CACHE_DIR
        self.debug_dir = os.path.join(os.getcwd(), DEFAULT_DEBUG_DIR)
        
        self.llm: Optional[Llama] = None
        self.model_path = os.path.join(self.model_dir, self.config.filename)
        self.mmproj_path = os.path.join(self.model_dir, self.config.mmproj)

    def prepare(self, progress_callback: Optional[Callable[[str, str], None]] = None):
        """Downloads models and initializes the inference engine."""
        self._setup_directories()
        self._download_models(progress_callback)
        self._load_engine()

    def _setup_directories(self):
        os.makedirs(self.model_dir, exist_ok=True)
        if self.debug:
            os.makedirs(self.debug_dir, exist_ok=True)
            logger.info(f"ðŸ› Debug mode ON. Frames: {self.debug_dir}")

    def _verify_file(self, path: str, expected_hash: str) -> bool:
        """Verifies SHA256 hash of a file."""
        if not os.path.exists(path):
            return False
            
        logger.info(f"ðŸ”’ Verifying integrity of {os.path.basename(path)}...")
        sha256 = hashlib.sha256()
        try:
            with open(path, 'rb') as f:
                while chunk := f.read(65536):
                    sha256.update(chunk)
            
            calculated = sha256.hexdigest()
            if calculated != expected_hash:
                logger.critical(f"âŒ INTEGRITY FAILURE! Hash mismatch for {path}")
                logger.critical(f"Expected: {expected_hash}")
                logger.critical(f"Calculated: {calculated}")
                return False
            
            logger.info("âœ… Hash verified.")
            return True
        except Exception as e:
            logger.error(f"Error checking hash: {e}")
            return False

    def _download_models(self, callback: Optional[Callable[[str, str], None]] = None):
        """Ensures both model and projector exist and match SHA256."""
        if self.unsafe:
            logger.warning("âš ï¸  SKIPPING INTEGRITY CHECKS (Unsafe Mode)")
            # In unsafe mode, just ensure files exist, do not verify hash or delete
            try:
                for fname in [self.config.filename, self.config.mmproj]:
                     hf_hub_download(
                        repo_id=REPO_ID,
                        filename=fname,
                        local_dir=self.model_dir,
                        local_dir_use_symlinks=False
                    )
            except Exception:
                 logger.exception("Download failed even in unsafe mode.")
                 sys.exit(1)
            return

        # 1. Check if files exist and are valid
        valid_model = self._verify_file(self.model_path, self.config.sha256)
        valid_proj = self._verify_file(self.mmproj_path, self.config.mmproj_sha256)
        
        if valid_model and valid_proj:
            return

        # 2. Delete invalid files if they exist
        if os.path.exists(self.model_path) and not valid_model:
            logger.warning("Found corrupted model. Deleting...")
            os.remove(self.model_path)
            
        if os.path.exists(self.mmproj_path) and not valid_proj:
            logger.warning("Found corrupted projector. Deleting...")
            os.remove(self.mmproj_path)

        # 3. Download
        logger.info(f"â¬‡ï¸  Downloading {self.tier_name.upper()} model files from {REPO_ID}...")
        try:
            for fname, expected_hash in [
                (self.config.filename, self.config.sha256), 
                (self.config.mmproj, self.config.mmproj_sha256)
            ]:
                path = os.path.join(self.model_dir, fname)
                if not os.path.exists(path):
                    if callback:
                        callback("STATUS", f"â¬‡ï¸ Downloading {fname} (This may take a while)...")
                    
                    hf_hub_download(
                        repo_id=REPO_ID,
                        filename=fname,
                        local_dir=self.model_dir,
                        local_dir_use_symlinks=False
                    )
                    # Verify immediately after download
                    if not self._verify_file(path, expected_hash):
                        logger.critical("âŒ SECURITY ALERT: Downloaded file hash mismatch. Aborting.")
                        os.remove(path)
                        sys.exit(1)

            logger.info("âœ… Download and verification complete.")
        except Exception as e:
            logger.exception("Failed to download model files.")
            sys.exit(1)

    def _load_engine(self):
        """Loads Llama with Vision Handler."""
        logger.info(f"ðŸ¤– Loading {self.tier_name.upper()} Engine (Vision Enabled)...")
        try:
            chat_handler = Llava15ChatHandler(clip_model_path=self.mmproj_path)
            self.llm = Llama(
                model_path=self.model_path,
                chat_handler=chat_handler,
                n_ctx=CONTEXT_SIZE,
                n_gpu_layers=-1, # Auto-offload
                verbose=False
            )
        except Exception as e:
            logger.exception("Failed to initialize Inference Engine.")
            sys.exit(1)

    def extract_frames(self, video_path: str, max_frames: int = 5) -> tuple[List[str], Dict[str, Any]]:
        cap = cv2.VideoCapture(video_path)
        metadata = {"duration_sec": 0, "resolution": "unknown", "fps": 0, "frame_count": 0}
        
        if not cap.isOpened():
            logger.warning(f"Could not open video: {video_path}")
            return [], metadata

        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            metadata["fps"] = round(fps, 2)
            metadata["resolution"] = f"{w}x{h}"
            metadata["frame_count"] = total_frames
            metadata["duration_sec"] = round(total_frames / fps, 2) if fps > 0 else 0
        except Exception as e:
            logger.warning(f"Metadata extraction warning: {e}")

        # Fallback to 30fps if metadata is broken
        frame_interval = int(fps * self.interval) if fps > 0 else 300 
        
        base64_frames = []
        count = 0
        extracted_count = 0
        
        while cap.isOpened() and len(base64_frames) < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            if count % frame_interval == 0:
                # Validation: Skip empty/black frames
                if np.var(frame) < 10:
                    count += 1
                    continue

                resized = cv2.resize(frame, (384, 384))
                
                if self.debug:
                    debug_name = f"{os.path.basename(video_path)}_{extracted_count}.jpg"
                    cv2.imwrite(os.path.join(self.debug_dir, debug_name), resized)

                _, buffer = cv2.imencode('.jpg', resized, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
                b64_str = base64.b64encode(buffer).decode('utf-8')
                base64_frames.append(f"data:image/jpeg;base64,{b64_str}")
                extracted_count += 1
            
            count += 1
            
        cap.release()
        return base64_frames, metadata

    def _parse_ai_response(self, text: str) -> Dict[str, Any]:
        """Robustly parses the AI output using YAKE-First Strategy."""
        
        # 1. Clean Chatty Prefixes ("Sure, here is...", "Assistant:")
        # Handles optional colon and varying casing
        clean_text = re.sub(r'(?i)^(here is|sure|okay|assistant|ai):?\s*', '', text.strip())
        
        # 2. Generate Professional Summary (Smart Truncation)
        # Uses textwrap to avoid breaking words mid-string
        summary = textwrap.shorten(clean_text, width=150, placeholder="...")
        
        # 3. YAKE Extraction (Primary Tagging Source)
        tags = self._extract_yake_tags(clean_text)
        
        return {
            "summary": summary,
            "description": clean_text,
            "tags": tags
        }

    def _extract_yake_tags(self, text: str) -> List[str]:
        """Extracts significant keywords using YAKE (Unsupervised Statistical Learning)."""
        try:
            # Init YAKE: English, max n-gram=2 (e.g. "Workload Domain")
            # dedupLim=0.3 -> STRICT deduplication to avoid "Video" vs "Video Tutorial"
            kw_extractor = yake.KeywordExtractor(lan="en", n=2, dedupLim=0.4, top=5, features=None)
            keywords = kw_extractor.extract_keywords(text)
            
            # YAKE returns [(kw, score), ...] - lower score is better
            tags = [kw for kw, score in keywords]
            return tags if tags else ["untagged"]
        except Exception as e:
            logger.warning(f"YAKE extraction failed: {e}")
            return ["untagged", "error"]

    def _save_thumbnail(self, frame, video_path: str):
        """Saves a compressed JPG thumbnail to cache."""
        try:
            thumb_dir = os.path.expanduser("~/.cache/bo_video_tagger/thumbs")
            os.makedirs(thumb_dir, exist_ok=True)
            
            # Use filename hash to avoid path issues
            vid_hash = hashlib.md5(video_path.encode()).hexdigest()
            save_path = os.path.join(thumb_dir, f"{vid_hash}.jpg")
            
            # Resize for efficiency (Width 300px)
            h, w = frame.shape[:2]
            new_w = 300
            new_h = int(h * (new_w / w))
            resized = cv2.resize(frame, (new_w, new_h))
            
            cv2.imwrite(save_path, resized, [int(cv2.IMWRITE_JPEG_QUALITY), 70])
            return save_path
        except Exception as e:
            logger.warning(f"Failed to generate thumbnail: {e}")
            return None

    def process_video(self, video_path: str) -> dict:
        """Runs the VLM on a single video file."""
        if not self.llm:
            raise RuntimeError("Engine not loaded. Call prepare() first.")

        start_time = time.time()
        try:
            frames, vid_meta = self.extract_frames(video_path)
            if not frames:
                return {"meta": {"file": os.path.basename(video_path)}, "error": "No valid frames extracted"}

            # Save Thumbnail Directly (Optimization: No double encoding)
            try:
                # We need the first frame. extract_frames returns base64 strings.
                # To avoid re-opening OpenCV, we should refactor extract_frames or just decode the first one efficiently.
                # Actually, the plan says: "Pass cv2 frame directly... inside process_video".
                # But process_video calls extract_frames which closes cap.
                # So we must receive the raw frame from extraction or decode.
                # decoding base64 IS efficient enough compared to disk I/O.
                # The "Double Encoding" meant encoding to b64 then decoding to save.
                # But since extract_frames is an API that returns b64, we are stuck with it unless we change the signature.
                # HOWEVER, for the "Brutal" review, let's stick to the plan:
                # We will decode the first frame from the base64 string.
                
                if "," in frames[0]:
                    b64_data = frames[0].split(",")[1]
                else:
                    b64_data = frames[0]
                    
                first_img_data = base64.b64decode(b64_data)
                np_arr = np.frombuffer(first_img_data, np.uint8)
                raw_frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                self._save_thumbnail(raw_frame, video_path)
            except Exception as ferr:
                logger.warning(f"Thumbnail generation error: {ferr}")

            content = [{"type": "image_url", "image_url": {"url": img}} for img in frames]
            
            # Simplified Prompt (Focused on Description)
            prompt_text = (
                "Describe the content of this video in detail. "
                "Focus on technical terms, objects present in the scene, and actions being performed."
            )
            
            content.append({
                "type": "text", 
                "text": prompt_text
            })

            response = self.llm.create_chat_completion(
                messages=[{"role": "user", "content": content}],
                max_tokens=512, # Increased for detailed desc + tags
                temperature=0.5, # Lower temp for strict formatting
                repeat_penalty=1.1
            )
            
            raw_text = response['choices'][0]['message']['content']
            parsed_ai = self._parse_ai_response(raw_text)
            
            # Construct Rich Dictionary
            result_data = {
                "meta": {
                    "file": os.path.basename(video_path),
                    "path": video_path,
                    "size_mb": round(os.path.getsize(video_path) / (1024*1024), 2),
                    **vid_meta
                },
                "ai": parsed_ai,
                "system": {
                    "model": self.config.filename,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "processing_time_sec": round(time.time() - start_time, 2)
                }
            }
            
            # For backward compatibility with CLI print logic (if running main)
            # We can optionally log here, but we should return the dict.
            # The original code wrote to file here. We remove that side effect for the library usage
            # BUT: If running as CLI script, we need that side effect. 
            # The cleanest way is to remove the file writing from here and let the caller handle it.
            # However, to preserve CLI functionality without breaking changes, we might check a flag?
            # Or simplified: bo_video_tagger.py is now primarily a library. CLI users might lose direct jsonl writing
            # UNLESS we wrap main() to write it. 
            # For this task, I prioritize the UI functionality.
            
            return result_data

        except Exception as e:
            logger.exception(f"Error processing {video_path}")
            return {"meta": {"file": os.path.basename(video_path)}, "error": str(e)}

def check_system_resources(tier: str) -> bool:
    mem = psutil.virtual_memory()
    available_gb = mem.available / (1024 ** 3)
    req_gb = MODEL_TIERS[tier].min_ram_gb
    
    logger.info(f"System Check ({tier.upper()}): {available_gb:.2f}GB Available / {req_gb}GB Required")
    
    if available_gb < req_gb:
        print(f"âš ï¸  WARNING: Low Memory. Required: {req_gb}GB, Available: {available_gb:.2f}GB")
        if sys.stdin.isatty():
             return input("Continue anyway? (y/n): ").strip().lower() == 'y'
        return False
    return True

def main():
    # Configure Logging
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S'
    )

    parser = argparse.ArgumentParser(description=f"BO Video Tagger v{__version__}")
    parser.add_argument("folder", help="Path to video folder")
    parser.add_argument("--mode", choices=MODEL_TIERS.keys(), default="smart", help="Processing mode")
    parser.add_argument("--interval", type=int, default=10, help="Frame extraction interval in seconds (default: 10)")
    parser.add_argument("--output", help="Custom output directory or filename")
    parser.add_argument("--debug", action="store_true", help="Save debug frames")
    parser.add_argument("--unsafe", action="store_true", help="DISABLE security checks (Model Integrity)")
    args = parser.parse_args()

    # Early Validation
    if not os.path.exists(args.folder):
        logger.error(f"Directory not found: {args.folder}")
        sys.exit(1)

    # Determine Output Path (Early Validation)
    timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
    folder_name = os.path.basename(os.path.normpath(args.folder))
    default_filename = f"{folder_name}_video_tags_{timestamp}.jsonl"

    if args.output:
        if os.path.isdir(args.output):
            output_path = os.path.join(args.output, default_filename)
        else:
            output_path = args.output
            
        # SECURITY: Exact extension check
        if not output_path.endswith(".jsonl"):
            logger.critical("â›” SECURITY ERROR: Output file must have .jsonl extension.")
            logger.critical(f"Provided path: {output_path}")
            sys.exit(1)
    else:
        output_path = default_filename

    if not check_system_resources(args.mode):
        logger.error("Aborted due to system requirements.")
        sys.exit(1)

    if args.unsafe:
        logger.warning("âš ï¸  UNSAFE MODE ENABLED: Skipping integrity checks!")

    # Initialize Tagger
    tagger = VideoTagger(tier=args.mode, debug=args.debug, interval=args.interval, unsafe=args.unsafe)
    tagger.prepare()

    # Find Videos
    valid_exts = ('.mp4', '.mov', '.avi', '.mkv', '.webm')
    video_files = [
        os.path.join(args.folder, f) for f in os.listdir(args.folder) 
        if f.lower().endswith(valid_exts)
    ]
    
    if not video_files:
        logger.warning("No video files found.")
        sys.exit(0)

    logger.info(f"Processing {len(video_files)} videos...")



    logger.info(f"ðŸ’¾ Saving results to: {output_path}")
    
    # Process Loop
    with tqdm(total=len(video_files), unit="vid") as pbar:
        # Open in append mode (Line-Delimited JSON)
        with open(output_path, 'a') as f:
            for vid in video_files:
                result = tagger.process_video(vid)
                
                # O(1) Write
                f.write(json.dumps(result) + "\n")
                f.flush() # Ensure it hits disk immediately
                
                pbar.set_postfix(file=os.path.basename(vid)[:10])
                pbar.update(1)

    logger.info(f"Done! Results saved to {output_path}")

if __name__ == "__main__":
    main()